@article{YOU2022410,
title = {Cluster center consistency guided sampling learning for multiple kernel clustering},
journal = {Information Sciences},
volume = {606},
pages = {410-422},
year = {2022},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2022.05.073},
url = {https://www.sciencedirect.com/science/article/pii/S0020025522005059},
author = {Jiali You and Yanglei Hou and Zhenwen Ren and Xiaojian You and Jian Dai and Yuancheng Yao},
keywords = {Multiple kernel clustering, Multi-view clustering, Anchor sampling, Cluster center consistency, Dictionary learning},
abstract = {Multiple kernel clustering (MKC) is popular in processing non-linear data over the past years. The main challenge is that the kernel matrix with the size n√ón leads to high memory and computational consumption, where n denotes the number of samples. Although the widely used static anchor sampling can mitigate such a challenging considerably, how to dynamically select anchor points with a learning manner from kernel matrix is a difficult problem. To address the issue, this paper proposes a novel method dubbed as cluster center consistency guided sampling learning (3CSL) for multiple kernel clustering (3CSL-MKC). Specifically, by taking the cluster center consistency between the original partial kernel data and anchor points into consideration, 3CSL-MKC learns the shared anchor sampling matrix gradually. With the help of high-quality anchors, the essential clustering information of each kernel partition can be transformed largely into a concentrated low-dimensional representation matrix. Meanwhile, based on dictionary learning, 3CSL-MKC fuses these candidate representation matrixes to produce the resulting consensus representation, such that the clustering assignments can be directly obtained relying on simple k-means. A large number of experiments are conducted on different multiple kernel datasets to verify the effectiveness and efficiency of the proposed method.}
}

@Article{You2023,
author={You, Jiali
and Han, Chiyu
and Ren, Zhenwen
and Li, Haoran
and You, Xiaojian},
title={Clustering via multiple kernel k-means coupled graph and enhanced tensor learning},
journal={Applied Intelligence},
year={2023},
month={Feb},
day={01},
volume={53},
number={3},
pages={2564-2575},
abstract={Kernel k-means based and spectral clustering (SC) based multi-kernel clustering (MKC) has been widely used in recent years due to the efficiency in grouping nonlinear data. However, (1) the methods based on the above two categories only focus on clustering indicator matrix learning or graph learning, few of them have noticed the connection between the two; and (2) it is hard for existing methods to consider the high-order similarities of all pre-defined base kernels, which leads to the waste of inter-kernel information. To solve these problems, we propose kernel k-means coupled graph and enhanced tensor learning (KKG-ETL). Concretely, a new graph learning paradigm, kernel k-means coupled graph (KKG), is proposed to establish the theoretical relation between clustering indicator matrix and affinity graph. Therefore, a better candidate affinity graph can be obtained for each base kernel. Then, enhanced tensor learning (ETL) is proposed to capture the high-order similarities of all candidate graphs via an auto-weighted Schatten p-norm. In this framework, we integrate the indication properties of kernel k-means and the manifold excavation capability of SC, while exploring the high-order similarities among all kernels. Comprehensive experiments on 8 widely used datasets verify the validity and feasibility of our proposed KKG-ETL.},
issn={1573-7497},
doi={10.1007/s10489-022-03679-x},
url={https://doi.org/10.1007/s10489-022-03679-x}
}

